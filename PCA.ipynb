{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17dcd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class PCA:\n",
    "    \"\"\"\n",
    "    Алгоритм анализа главных компонент (PCA) - техника понижения размерности.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_components : int\n",
    "        Количество главных компонент.\n",
    "        Если n_components не задано, то все компоненты сохраняются.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    mean_ : ndarray размера (n_features,)\n",
    "        Эмпирическое среднее значение для каждого признака, рассчитанное на основе обучающей выборки.\n",
    "\n",
    "    components_ : ndarray размера (n_features, n_components)\n",
    "        Главные оси в пространстве признаков, представляющие направления максимальной дисперсии.\n",
    "\n",
    "    explained_variance_ : ndarray размера (n_components,)\n",
    "        Величина отклонения, охватываемая каждым из выбранных компонентов.\n",
    "\n",
    "    explained_variance_ratio_ : ndarray размера (n_components,)\n",
    "        Процент отклонения, объясняемый каждым из выбранных компонентов.\n",
    "        Если параметр Of_components не задан, тогда сохраняются все компоненты, и сумма коэффициентов равна 1,0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components: Optional[int] = None):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        Обучение модели на матрице X, выполнив разложение по ковариационной матрице.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray размера (n_samples, n_features)\n",
    "            Обучающая выборка.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Возвращает сам объект.\n",
    "        \"\"\"\n",
    "        # Расчет среднего\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "\n",
    "        # Центрирование данных\n",
    "        X = X - self.mean_\n",
    "\n",
    "        # Расчет ковариационной матрицы\n",
    "        n = X.shape[0]\n",
    "        cov_matrix = np.dot(X.T, X) / (n - 1)\n",
    "\n",
    "        # Расчет собственных значений и собствнных векторов\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "        # Сортировка собствнных векторов в порядке убывания\n",
    "        idx = np.argsort(eigenvalues)[::-1]\n",
    "        self.components_ = eigenvectors[:, idx]\n",
    "\n",
    "        # Вычислить дисперсию\n",
    "        self.explained_variance_ = eigenvalues[idx]\n",
    "        self.explained_variance_ratio_ = self.explained_variance_ / np.sum(self.explained_variance_)\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Применение уменьшения размерности к X.\n",
    "\n",
    "        X проецируется на первые основные компоненты, ранее полученные из обучающего набора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray размера (n_samples, n_features)\n",
    "            Новые данные.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_new : ndarray размера (n_samples, n_components)\n",
    "            Преобразованные значения.\n",
    "        \"\"\"\n",
    "        # Центрирование данных\n",
    "        X = X - self.mean_\n",
    "\n",
    "        # Преобразованные данные\n",
    "        return np.dot(X, self.components_[:, :self.n_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5189f584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA with all components\n",
      "--------\n",
      "{'n_components': None, 'mean_': array([5.35, 4.85, 6.  ]), 'components_': array([[ 0.61498811,  0.78390513,  0.08533678],\n",
      "       [ 0.54615757, -0.34539208, -0.76316199],\n",
      "       [ 0.56877195, -0.51594288,  0.64054774]]), 'explained_variance_': array([1.91108305e+01, 7.00085066e+00, 1.65216263e-03]), 'explained_variance_ratio_': array([7.31841863e-01, 2.68094868e-01, 6.32689290e-05])}\n",
      "0.9999999999999999\n",
      "(4, 3) (4, 3)\n",
      "[[-5.70131120e+00 -8.24198801e-01  2.73303455e-02]\n",
      " [-1.20202253e-01 -1.36648307e+00 -5.72315460e-02]\n",
      " [ 4.89419870e+00 -1.73806945e+00  3.05558775e-02]\n",
      " [ 9.27314752e-01  3.92875132e+00 -6.54677013e-04]]\n",
      "--------\n",
      "\n",
      "PCA with 1 component\n",
      "--------\n",
      "{'n_components': 1, 'mean_': array([5.35, 4.85, 6.  ]), 'components_': array([[ 0.61498811,  0.78390513,  0.08533678],\n",
      "       [ 0.54615757, -0.34539208, -0.76316199],\n",
      "       [ 0.56877195, -0.51594288,  0.64054774]]), 'explained_variance_': array([1.91108305e+01, 7.00085066e+00, 1.65216263e-03]), 'explained_variance_ratio_': array([7.31841863e-01, 2.68094868e-01, 6.32689290e-05])}\n",
      "0.9999999999999999\n",
      "(4, 3) (4, 1)\n",
      "[[-5.7013112 ]\n",
      " [-0.12020225]\n",
      " [ 4.8941987 ]\n",
      " [ 0.92731475]]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [1.2, 2, 3.2],\n",
    "        [4.2, 5.3, 6.6],\n",
    "        [7, 8.1, 9.7],\n",
    "        [9, 4, 4.5],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"PCA with all components\")\n",
    "print(\"--------\")\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "X_projected = pca.transform(X)\n",
    "print(pca.__dict__)\n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(X.shape, X_projected.shape)\n",
    "print(X_projected)\n",
    "print(\"--------\\n\")\n",
    "\n",
    "print(\"PCA with 1 component\")\n",
    "print(\"--------\")\n",
    "pca = PCA(1)\n",
    "pca.fit(X)\n",
    "X_projected = pca.transform(X)\n",
    "print(pca.__dict__)\n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(X.shape, X_projected.shape)\n",
    "print(X_projected)\n",
    "print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb89bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDPCA:\n",
    "    \"\"\"\n",
    "    Алгоритм анализа главных компонент (PCA) - техника понижения размерности.\n",
    "\n",
    "    Использование сингулярного разложения (SVD) для выполнения PCA.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_components : int\n",
    "        Количество главных компонент.\n",
    "        Если n_components не задано, то все компоненты сохраняются.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    mean_ : ndarray размера (n_features,)\n",
    "        Эмпирическое среднее значение для каждого признака, рассчитанное на основе обучающей выборки.\n",
    "\n",
    "    components_ : ndarray размера (n_features, n_components)\n",
    "        Главные оси в пространстве признаков, представляющие направления максимальной дисперсии.\n",
    "\n",
    "    explained_variance_ : ndarray размера (n_components,)\n",
    "        Величина отклонения, охватываемая каждым из выбранных компонентов.\n",
    "\n",
    "    explained_variance_ratio_ : ndarray размера (n_components,)\n",
    "        Процент отклонения, объясняемый каждым из выбранных компонентов.\n",
    "        Если параметр Of_components не задан, тогда сохраняются все компоненты, и сумма коэффициентов равна 1,0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components: Optional[int] = None):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Обучение модели на матрице X, выполнив разложение по ковариационной матрице.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray размера (n_samples, n_features)\n",
    "            Обучающая выборка.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Возвращает сам объект.\n",
    "        \"\"\"\n",
    "        # Расчет среднего\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "\n",
    "        # Центрирование данных\n",
    "        X = X - self.mean_\n",
    "\n",
    "        # SVD разложение\n",
    "        _, S, Vt = np.linalg.svd(X)\n",
    "\n",
    "        # Выбор первых n_components\n",
    "        self.components_ = Vt[:self.n_components].T\n",
    "\n",
    "        # Вычислить дисперсию\n",
    "        n = X.shape[0]\n",
    "        self.explained_variance_ = (S ** 2) / (n - 1)\n",
    "        self.explained_variance_ratio_ = self.explained_variance_ / np.sum(self.explained_variance_)\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Применение уменьшения размерности к X.\n",
    "\n",
    "        X проецируется на первые основные компоненты, ранее полученные из обучающего набора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray размера (n_samples, n_features)\n",
    "            Новые данные.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_new : ndarray размера (n_samples, n_components)\n",
    "            Преобразованные значения.\n",
    "        \"\"\"\n",
    "        # Центрирование данных\n",
    "        X = X - self.mean_\n",
    "\n",
    "        # Преобразованные данные\n",
    "        return np.dot(X, self.components_[:, :self.n_components])  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a58f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA with all components\n",
      "--------\n",
      "{'n_components': None, 'mean_': array([5.35, 4.85, 6.  ]), 'components_': array([[ 0.61498811, -0.78390513, -0.08533678],\n",
      "       [ 0.54615757,  0.34539208,  0.76316199],\n",
      "       [ 0.56877195,  0.51594288, -0.64054774]]), 'explained_variance_': array([1.91108305e+01, 7.00085066e+00, 1.65216263e-03]), 'explained_variance_ratio_': array([7.31841863e-01, 2.68094868e-01, 6.32689290e-05])}\n",
      "1.0\n",
      "(4, 3) (4, 3)\n",
      "[[-5.70131120e+00  8.24198801e-01 -2.73303455e-02]\n",
      " [-1.20202253e-01  1.36648307e+00  5.72315460e-02]\n",
      " [ 4.89419870e+00  1.73806945e+00 -3.05558775e-02]\n",
      " [ 9.27314752e-01 -3.92875132e+00  6.54677013e-04]]\n",
      "--------\n",
      "\n",
      "PCA with 1 component\n",
      "--------\n",
      "{'n_components': 1, 'mean_': array([5.35, 4.85, 6.  ]), 'components_': array([[0.61498811],\n",
      "       [0.54615757],\n",
      "       [0.56877195]]), 'explained_variance_': array([1.91108305e+01, 7.00085066e+00, 1.65216263e-03]), 'explained_variance_ratio_': array([7.31841863e-01, 2.68094868e-01, 6.32689290e-05])}\n",
      "1.0\n",
      "(4, 3) (4, 1)\n",
      "[[-5.7013112 ]\n",
      " [-0.12020225]\n",
      " [ 4.8941987 ]\n",
      " [ 0.92731475]]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [1.2, 2, 3.2],\n",
    "        [4.2, 5.3, 6.6],\n",
    "        [7, 8.1, 9.7],\n",
    "        [9, 4, 4.5],\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"PCA with all components\")\n",
    "print(\"--------\")\n",
    "pca = SVDPCA()\n",
    "pca.fit(X)\n",
    "X_projected = pca.transform(X)\n",
    "print(pca.__dict__)\n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(X.shape, X_projected.shape)\n",
    "print(X_projected)\n",
    "print(\"--------\\n\")\n",
    "\n",
    "print(\"PCA with 1 component\")\n",
    "print(\"--------\")\n",
    "pca = SVDPCA(1)\n",
    "pca.fit(X)\n",
    "X_projected = pca.transform(X)\n",
    "print(pca.__dict__)\n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(X.shape, X_projected.shape)\n",
    "print(X_projected)\n",
    "print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2799be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from PIL import Image\n",
    "from PIL.Image import Image as PILImage\n",
    "\n",
    "\n",
    "class ImagePCA:\n",
    "    \"\"\"\n",
    "    Сжимает изображение с помощью PCA и восстанавливает его при вызове.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    img_path_ : str\n",
    "        Сохраняет путь к файлу изображения.\n",
    "        Загружается изображение в формате jpg, имеющее форму (H, W, 3)\n",
    "    n_components_ : int\n",
    "        Количество основных компонентов, используемых для сжатия.\n",
    "    mean_ : ndarray размера (W, 3)\n",
    "        Среднее значение исходного изображения, используемого для центрирования.\n",
    "    Y_ : ndarray размера (3, H, n_components_)\n",
    "        Сжатые данные изображения после применения PCA.\n",
    "    Vt_ : ndarray размера (3, n_components_, W)\n",
    "        Топ n основных компонентов SVD.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_path: str, n_components: int) -> None:\n",
    "        self.img_path_ = img_path\n",
    "        self.n_components_ = n_components\n",
    "\n",
    "        self._compress()\n",
    "\n",
    "    def _compress(self) -> None:\n",
    "        \"\"\"        \n",
    "        Сжатие изображения с использованием SVD разложения.\n",
    "\n",
    "        Сначала изображение преобразуется в массив и центрируется. Затем применяется SVD\n",
    "        для сжатия данных изображения. Этот метод устанавливает атрибуты Y_ и Vt_ .\n",
    "        \"\"\"\n",
    "        with Image.open(self.img_path_) as img:\n",
    "            img = np.array(img)\n",
    "\n",
    "        self.mean_ = img.mean(axis=0)\n",
    "        img = img - self.mean_\n",
    "        img = np.moveaxis(img, 2, 0)\n",
    "\n",
    "        _, _, Vt = np.linalg.svd(img)\n",
    "\n",
    "        Vt_ = Vt[:, : self.n_components_]\n",
    "        Y_ = np.matmul(img, Vt_.transpose(0, 2, 1))\n",
    "\n",
    "        self.Y_ = Y_\n",
    "        self.Vt_ = Vt_\n",
    "\n",
    "    def __call__(self) -> PILImage:\n",
    "        \"\"\"        \n",
    "        Восстанвление сжатого изображения.\n",
    "\n",
    "        Когда вызывается экземпляр, он восстанавливает изображение из сжатых данных\n",
    "        и возвращает его как объект PIL Image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        PILImage\n",
    "            Восстановленное изображение после сжатия алгоритмом PCA.\n",
    "        \"\"\"\n",
    "        img_ = np.matmul(self.Y_, self.Vt_)\n",
    "        img_ = img_.transpose(1, 2, 0)\n",
    "        img_ += self.mean_\n",
    "        img_ = img_.clip(0, 255)\n",
    "        img_ = img_.astype(np.uint8)\n",
    "        return Image.fromarray(img_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80449bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"mug.jpg\"\n",
    "n_components = 64\n",
    "\n",
    "img_pca = ImagePCA(img_path, n_components)\n",
    "img = img_pca()\n",
    "\n",
    "img.save(\"reconstructed.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e93375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
